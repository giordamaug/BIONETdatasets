{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40966,"status":"ok","timestamp":1649407374487,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"},"user_tz":-120},"id":"66HJCU-fTjNn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"26aa7803-2a53-4357-cf51-3c9b85760d40"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 7.9 MB 5.9 MB/s \n","\u001b[K     |████████████████████████████████| 3.5 MB 4.5 MB/s \n","\u001b[K     |████████████████████████████████| 2.5 MB 3.9 MB/s \n","\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n","!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"]},{"cell_type":"markdown","metadata":{"id":"MNgwF_IjTjNq"},"source":["# Loading required libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddc1yRocTjNr"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","import random\n","import numpy as np\n","import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","def set_seed(seed=1):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","\n","set_seed()"]},{"cell_type":"markdown","metadata":{"id":"jwXYNEIFff-l"},"source":["# Download dataset from Github"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1477,"status":"ok","timestamp":1649408271678,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"},"user_tz":-120},"id":"ykT1KO_4eqvK","outputId":"5212ac38-bed4-4712-fd02-0aea4489cf2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-08 08:57:49--  https://raw.githubusercontent.com/giordamaug/BIONETdatasets/main/CSV/integratedcrispr/edges_integrated2.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 39025931 (37M) [text/plain]\n","Saving to: ‘edges_integrated2.csv.1’\n","\n","edges_integrated2.c 100%[===================>]  37.22M   161MB/s    in 0.2s    \n","\n","2022-04-08 08:57:50 (161 MB/s) - ‘edges_integrated2.csv.1’ saved [39025931/39025931]\n","\n","--2022-04-08 08:57:50--  https://raw.githubusercontent.com/giordamaug/BIONETdatasets/main/CSV/integratedcrispr/nodes_integrated2_update_attr_label_avana0_wang_crispr.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10647374 (10M) [text/plain]\n","Saving to: ‘nodes_integrated2_update_attr_label_avana0_wang_crispr.csv.2’\n","\n","nodes_integrated2_u 100%[===================>]  10.15M  --.-KB/s    in 0.1s    \n","\n","2022-04-08 08:57:51 (90.4 MB/s) - ‘nodes_integrated2_update_attr_label_avana0_wang_crispr.csv.2’ saved [10647374/10647374]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/giordamaug/BIONETdatasets/main/CSV/integratedcrispr/edges_integrated2.csv\n","!wget https://raw.githubusercontent.com/giordamaug/BIONETdatasets/main/CSV/integratedcrispr/nodes_integrated2_update_attr_label_avana0_wang_crispr.csv"]},{"cell_type":"markdown","source":["## To iterate your experiments, select your choice and run from thic cell on..."],"metadata":{"id":"I-5i61T36h9u"}},{"cell_type":"markdown","metadata":{"id":"dL6HwnA8Y1vv"},"source":["# Load the attributes and labels from CSV\n","\n","All node/gene attributes and labels are in one file. First we devide attributes (numeric) from labels (non-numeric) columns.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UpDEhD9Cfu8l"},"outputs":[],"source":["import pandas as pd\n","from sklearn import preprocessing\n","node_name, label_name = 'name', 'label_CS_ACH_most_freq'\n","# read node attributes\n","df = pd.read_csv('/content/nodes_integrated2_update_attr_label_avana0_wang_crispr.csv', \n","                 sep='\\t', index_col=node_name)   # load csv and set 'name' as index\n","x = df.select_dtypes(include=np.number)           # Attributes are numeric columns\n","labels = df.select_dtypes(exclude=np.number)      # labels are not numeric columns"]},{"cell_type":"markdown","metadata":{"id":"T-NvE8jjgL8h"},"source":["# Set the label\n","The label is one column or a grouping of values from one label column. In the paper we considered the ten values of `label_CS_ACH_most_freq`, and we grouped as following:\n","*   `CS0` = `E`ssential class\n","*   `CS6`-`CS9` = `NE` non essential class\n","\n","The new label name is `CS0_vs_CS6-9`\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":376,"status":"ok","timestamp":1649408283172,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"},"user_tz":-120},"id":"-v8d4IUvF9Yj","outputId":"6af05b35-908b-438a-b72e-384f107eb9f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Selected 3814 genes\n"]}],"source":["E_class, NE_class = ['CS0'], ['CS6', 'CS7', 'CS8', 'CS9']\n","new_label_name = 'CS0_vs_CS6-9'\n","labels[new_label_name] = labels.apply(lambda row: 'E' if row[label_name] in E_class \\\n","                                      else 'NE' if row[label_name] in NE_class \\\n","                                      else row[label_name], axis=1)\n","labels = labels[labels[new_label_name].isin(['E', 'NE']) == True]       # drop any row contaning NaN or SC1-SC5 as value\n","genes = labels.index.values\n","print(f'Selected {len(genes)} genes')"]},{"cell_type":"markdown","metadata":{"id":"5snibVTZIm-d"},"source":["# Encode the label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":358,"status":"ok","timestamp":1649408286033,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"},"user_tz":-120},"id":"AG6j1sAJfgAS","outputId":"1b0e3345-f0dd-4409-bd1e-7d2b72af836e"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'E': 0, 'NE': 1} Counter({1: 3069, 0: 745})\n"]}],"source":["from sklearn import preprocessing\n","from collections import Counter\n","encoder = preprocessing.LabelEncoder()\n","y = encoder.fit_transform(labels[new_label_name].values)  \n","classes_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n","print(classes_mapping, Counter(y))"]},{"cell_type":"markdown","metadata":{"id":"KGZqjWBcmNM6"},"source":["# Load the PPI network\n","The PPI networks is loaded from a CSV file, where\n","*   `A` is the column name for edge source (gene name)\n","*   `B` is the column name for edge target (gene name)\n","*   `weight` is the column name for edge weight\n","Only some method use the PPI netoworks, as an example all GCN methods, and Node2Vec.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ku9EUnJfmMF4"},"outputs":[],"source":["ppi = pd.read_csv('/content/edges_integrated2.csv', sep='\\t')              # read ppi from CSV file\n","ppi = ppi.loc[((ppi['A'].isin(genes)) & (ppi['B'].isin(genes)))]           # reduce PPI only to selected nodes/genes\n","idxlbl = labels.reset_index(drop=True)\n","idxlbl[node_name] = labels.index\n","map_gene_to_idx = { v[node_name]: i  for i,v in idxlbl.to_dict('Index').items() }\n","vfunc = np.vectorize(lambda t: map_gene_to_idx[t])\n","edges_index = torch.from_numpy(vfunc(ppi[['A','B']].to_numpy().T)) "]},{"cell_type":"markdown","source":["## Normalize edge weights"],"metadata":{"id":"wlOsdSe83F66"}},{"cell_type":"code","source":["#@title Normalization edges { form-width: \"30%\" }\n","normalize_edge = \"minmax\" #@param [\"\", \"zscore\", \"minmax\"]\n","if normalize_edge == 'minmax':\n","    maximum = ppi.loc[ppi['weight'] != np.inf, 'weight'].max()   # get max other than infinity\n","    minimum = ppi.loc[ppi['weight'] != np.nan, 'weight'].min()   # get min other than NaN\n","    ppi['weight'].replace(np.inf,maximum,inplace=True)             # replace ininity with max\n","    ppi['weight'].replace(np.nan,minimum,inplace=True)             # replace NaN with min\n","    ppi['weight'] = (ppi['weight'] - minimum) / (maximum - minimum)\n","elif normalize_edge == 'zscore':\n","    ppi['weight'] = (ppi['weight'] - ppi['weight'].mean()) / ppi['weight'].std()    "],"metadata":{"id":"rOKgNteJ3KEn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vmbko7ys1m-d"},"source":["# Select attributes to be used\n","We identified three sets of attributes:\n","1. bio attributes, related to gene information (such as, expression, etc.)\n","2. net attributes, derived from role of gene/node in the network (such as, degree, centrality, etc.)\n","3. GTEX-* attribute, additional biological information of genes \n","\n","In this code snippets the sets of attibutes are defines, and you may choose to subtract some of them from the matrix of node attributes \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1eTV5Ky2R9_"},"outputs":[],"source":["#@title Choose attributes { form-width: \"20%\" }\n","import re\n","bio_attr = False #@param {type:\"boolean\"}\n","net_attr = True #@param {type:\"boolean\"}\n","gtex_attr = False #@param {type:\"boolean\"}\n","bio_attributes = ['gc_content', 'Gtex_kidney', 'gene_disease_ass_count', 'oncodb_expression','orth_count', 'gene_length', \\\n","       'HPA_kidney', 'mf_coal', 'bp_coal', 'cc_coal', 'biogrid_coal', 'kegg_coal', 'reactome_coal', 'ucsc_tfbs_coal', \\\n","       'up_tissue_coal', 'transcript_count']  if bio_attr else []\n","net_attributes = ['degree', 'ecc', 'clos', 'betw', 'eigen', 'hub', 'trans', 'PR', 'triangles_numb', 'motif1', \\\n","        'motif2', 'motif3', 'motif5', 'strength'] if net_attr else []\n","r = re.compile('^GTEX*')\n","gtex_attributes = list(filter(r.match, x.columns)) if gtex_attr else []\n","x = x.filter(items=bio_attributes+gtex_attributes+net_attributes)"]},{"cell_type":"markdown","metadata":{"id":"B_Pz7CiWtKa3"},"source":["## Normalize attributes\n","In this snippet of code the matrix of node attributes is corrected by filling NaN with themean in the columns, while Infinte value with maximum. \n","\n","The attribute matrix is also reduce by removing all rows correspondning to node not considered, i.e. deleted becaus no label was associated to them."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1649408300592,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"},"user_tz":-120},"id":"pUXJiVentM44","outputId":"fe4dae38-dc5c-45a2-9236-f00d4cf6467e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fixing NaN and infinity in X matrix...Found 214 NaN values and 0 Inf values\n","X attributes normalization (zscore)...\n","New attribute matrix x(3814, 14)\n"]}],"source":["#@title Normalization nodes { form-width: \"30%\" }\n","normalize_node = \"zscore\" #@param [\"\", \"zscore\", \"minmax\"]\n","print(f'Fixing NaN and infinity in X matrix...', end='')\n","print(f'Found {x.isnull().sum().sum()} NaN values and {np.isinf(x).values.sum()} Inf values')\n","highest_non_inf = x.max().loc[lambda v: v<np.Inf].max()    # fix infinity (replace with max)\n","x.replace(np.Inf, highest_non_inf)\n","for col in x.columns[x.isna().any()].tolist():\n","  mean_value=x[col].mean()          # Replace NaNs in column with the  mean of values in the same column\n","  if mean_value is not np.nan:\n","    x[col].fillna(value=mean_value, inplace=True)\n","  else:\n","    x = x.drop(col, 1)\n","\n","if normalize_node == 'minmax':\n","  print(\"X attributes normalization (minmax)...\")\n","  x = (x-x.min())/(x.max()-x.min())\n","elif normalize_node == 'zscore':\n","  print(\"X attributes normalization (zscore)...\")\n","  x = (x-x.mean())/x.std()\n","x = x.loc[genes]\n","print(f'New attribute matrix x{x.shape}')"]},{"cell_type":"markdown","metadata":{"id":"KjmGrRxKqYU5"},"source":["# Build PyG storage for network"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-T0ncbRhqYU5","executionInfo":{"status":"ok","timestamp":1649408304730,"user_tz":-120,"elapsed":6,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"}},"outputId":"9558ae8c-f721-4099-cf37-e06e426530f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Data(x=[3814, 14], edge_index=[2, 107513], edge_attr=[107513], y=[3814], num_classes=2, train_mask=[3814], val_mask=[3814], test_mask=[3814], train_idx=[2314], val_idx=[500], test_idx=[1000])\n","===========================================================================================================\n","Number of nodes: 3814\n","Number of node features: 14\n","Number of {'E': 0, 'NE': 1} classes: 2\n","Class distritions: Counter({1: 3069, 0: 745})\n","Number of edges: 107513\n","Nodes indices: [   0    1    2 ... 3811 3812 3813]\n","Average node degree: 28.19\n","Number of training nodes: 2314\n","Training node indices: tensor([   2,    3,    4,  ..., 3809, 3810, 3811])\n","Training node label rate: 0.61\n","Has isolated nodes: True\n","Has edge weights: tensor([0.0413, 0.0338, 0.0395,  ..., 0.0003, 0.0066, 0.0047])\n","Has self-loops: False\n","Is directed: True\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import random\n","from tqdm import tqdm\n","import sys\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","from sklearn import metrics\n","from sklearn import preprocessing\n","from collections import Counter\n","\n","import seaborn as sns\n","\n","import torch\n","import torch.nn.functional as F\n","\n","import torch.optim as optim\n","from torch_geometric.data import Data\n","from torch_geometric.transforms import RandomNodeSplit\n","import torch.nn.functional as F\n","encoder = preprocessing.LabelEncoder()\n","y = encoder.fit_transform(labels[new_label_name].values)\n","classes_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n","data = Data(x=torch.from_numpy(x.to_numpy()).float(), edge_index=edges_index, edge_attr=torch.from_numpy(ppi['weight'].values).float(), y = torch.from_numpy(y))\n","data.num_classes = len(np.unique(y))\n","tfs =  RandomNodeSplit()\n","tfs(data)\n","\n","train_indices = np.arange(0,len(data.x))\n","data.train_idx = torch.tensor(train_indices[data.train_mask], dtype=torch.long)\n","data.val_idx = torch.tensor(train_indices[data.val_mask], dtype=torch.long)\n","data.test_idx = torch.tensor(train_indices[data.test_mask], dtype=torch.long)\n","\n","print()\n","print(data)\n","print('===========================================================================================================')\n","\n","# Gather some statistics about the graph.\n","print(f'Number of nodes: {data.num_nodes}')\n","print(f'Number of node features: {data.num_features}')\n","print(f'Number of {classes_mapping} classes: {data.num_classes}')\n","print(f'Class distritions: {Counter(data.y.numpy())}')\n","print(f'Number of edges: {data.num_edges}')\n","print(f'Nodes indices: {train_indices}')\n","print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n","print(f'Number of training nodes: {data.train_mask.sum()}')\n","print(f'Training node indices: {data.train_idx}')\n","print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n","print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n","print(f'Has edge weights: {data.edge_attr}')\n","print(f'Has self-loops: {data.has_self_loops()}')\n","print(f'Is directed: {data.is_directed()}')"]},{"cell_type":"markdown","metadata":{"id":"8ucyeYkxqYU5"},"source":["# The Trainer class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JdeDDnoAqYU6"},"outputs":[],"source":["import copy\n","from dataclasses import dataclass\n","import os\n","\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam, lr_scheduler\n","from tqdm import tqdm\n","\n","from sklearn import metrics\n","\n","@dataclass\n","class RunConfig:  # default parameters from the paper and official implementation\n","    learning_rate: float = 0.01\n","    num_epochs: int = 200\n","    weight_decay: float = 5e-4\n","    num_warmup_steps: int = 0\n","    save_each_epoch: bool = False\n","    output_dir: str = \".\"\n","\n","class Trainer:\n","    def __init__(self, model):\n","        self.model = model\n","\n","    def train(self, features, train_labels, val_labels, edge_index, edge_weights, device, run_config, log=True, eval_train=False):\n","        self.model = self.model.to(device)\n","        features = features.to(device)\n","        train_labels = train_labels.to(device)\n","        val_labels = val_labels.to(device)\n","        edge_index = edge_index.to(device)  # edhe list and weight\n","        edge_weights = edge_weights.to(device)\n","\n","        optimizer = Adam(self.model.parameters(), lr=run_config.learning_rate, weight_decay=run_config.weight_decay)\n","\n","        # https://huggingface.co/transformers/_modules/transformers/optimization.html#get_linear_schedule_with_warmup\n","        def lr_lambda(current_step: int):\n","            if current_step < run_config.num_warmup_steps:\n","                return float(current_step) / float(max(1, run_config.num_warmup_steps))\n","            return max(0.0, float(run_config.num_epochs - current_step) /\n","                       float(max(1, run_config.num_epochs - run_config.num_warmup_steps)))\n","\n","        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)\n","\n","        if log:\n","            print(\"Training started:\")\n","            print(f\"\\tNum Epochs = {run_config.num_epochs}\")\n","\n","        best_loss, best_model_accuracy = float(\"inf\"), 0\n","        best_model_state_dict = None\n","        if log: train_iterator = tqdm(range(0, int(run_config.num_epochs)))\n","        else: train_iterator = range(0, int(run_config.num_epochs))\n","        train_logs = {'train loss' : [], 'train acc' : [], 'train mcc' : [], 'val loss' : [],  'val acc' : [], 'val mcc' : []}\n","        for epoch in train_iterator:\n","            self.model.train()\n","            outputs = self.model(features, edge_index, edge_weights, train_labels)\n","            loss = outputs[1]\n","\n","            self.model.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","            if eval_train: train_loss, train_accuracy, train_mcc, _ , _ = self.evaluate(features, train_labels, edge_index, edge_weights, device)\n","            val_loss, val_accuracy, val_mcc, _ , _= self.evaluate(features, val_labels, edge_index, edge_weights, device)\n","            if log: train_iterator.set_description(f\"Training loss = {loss.item():.4f}, \" f\"val loss = {val_loss:.4f}, val acc = {val_accuracy:.2f}, val mcc = {val_mcc:.2f}\")\n","\n","            save_best_model = val_loss < best_loss\n","            if save_best_model:\n","                best_loss = val_loss\n","                best_model_accuracy = val_accuracy\n","                best_model_state_dict = copy.deepcopy(self.model.state_dict())\n","            if save_best_model or run_config.save_each_epoch or epoch + 1 == run_config.num_epochs:\n","                output_dir = os.path.join(run_config.output_dir, f\"Epoch_{epoch + 1}\")\n","                #self.save(output_dir)\n","            if eval_train:\n","                train_logs['train loss'].append(train_loss)\n","                train_logs['train acc'].append(train_accuracy)\n","                train_logs['train mcc'].append(train_mcc)\n","            train_logs['val loss'].append(val_loss)\n","            train_logs['val acc'].append(val_accuracy)\n","            train_logs['val mcc'].append(val_mcc)\n","        if log:\n","            print(f\"Best model val CE loss = {best_loss:.4f}, best model val accuracy = {best_model_accuracy:.2f}\")\n","        # reloads the best model state dict, bit hacky :P\n","        self.model.load_state_dict(best_model_state_dict)\n","        return train_logs \n","\n","    def evaluate(self, features, test_labels, edge_index, edge_weights, device):\n","        features = features.to(device)\n","        test_labels = test_labels.to(device)\n","        edge_index = edge_index.to(device)  # edhe list and weight\n","        edge_weights = edge_weights.to(device)\n","\n","        self.model.eval()\n","\n","        outputs = self.model(features, edge_index, edge_weights, test_labels)\n","        ce_loss = outputs[1].item()\n","\n","        ignore_label = nn.CrossEntropyLoss().ignore_index\n","        predicted_label = torch.max(outputs[0], dim=1).indices[test_labels != ignore_label]\n","        true_label = test_labels[test_labels != -100]\n","        accuracy = torch.mean((true_label == predicted_label).type(torch.FloatTensor)).item()\n","        mcc = metrics.matthews_corrcoef(true_label, predicted_label)\n","        cm = metrics.confusion_matrix(true_label, predicted_label)\n","        return ce_loss, accuracy, mcc, cm, predicted_label \n","\n","    def save(self, output_dir):\n","        if not os.path.isdir(output_dir):\n","            os.makedirs(output_dir)\n","\n","        model_path = os.path.join(output_dir, \"model.pth\")\n","        torch.save(self.model.state_dict(), model_path)"]},{"cell_type":"markdown","metadata":{"id":"FwBeBCdqqYU7"},"source":["# The model GNN "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZE2bxnYwqYU8"},"outputs":[],"source":["from torch_geometric.nn import GCNConv, GATConv, ChebConv\n","import torch.nn as nn\n","from torch_geometric.nn import GraphUNet\n","from torch_geometric.utils import dropout_adj\n","\n","use_gdc = True\n","weights=torch.tensor([round(Counter(data.y.numpy())[classes_mapping['NE']]/len(data.y),2), round(Counter(data.y.numpy())[classes_mapping['E']]/len(data.y),2)])\n","#weights = None\n","\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    #print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","\n","class ChebNetGCN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, num_hidden_layers=0, dropout=0.1, residual=False, k=2):\n","        super(ChebNetGCN, self).__init__()\n","\n","        self.dropout = dropout\n","        self.residual = residual\n","\n","        self.input_conv = ChebConv(input_size, hidden_size, k)\n","        self.hidden_convs = nn.ModuleList([ChebConv(hidden_size, hidden_size, k) for _ in range(num_hidden_layers)])\n","        self.output_conv = ChebConv(hidden_size, output_size, k)\n","\n","    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_weight: torch.Tensor, labels: torch.Tensor = None):\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = F.relu(self.input_conv(x, edge_index, edge_weight))\n","        for conv in self.hidden_convs:\n","            if self.residual:\n","                x = F.relu(conv(x, edge_index, edge_weight)) + x\n","            else:\n","                x = F.relu(conv(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = self.output_conv(x, edge_index, edge_weight)\n","\n","        if labels is None:\n","            return x\n","\n","        loss = nn.CrossEntropyLoss()(x, labels)\n","        return x, loss\n","\n","class GAT(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, dropout=0.1):\n","        super(GAT, self).__init__()\n","        torch.manual_seed(42)\n","\n","        self.conv1 = GATConv(input_size, hidden_size, heads=hidden_size, edge_dim=1, dropout=0.6)\n","        # On the Pubmed dataset, use heads=8 in conv2.\n","        self.conv2 = GATConv(hidden_size * hidden_size, output_size, heads=1, edge_dim=1, concat=False,\n","                             dropout=0.6)\n","        self.elu = nn.ELU()\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_weight: torch.Tensor, labels: torch.Tensor = None):\n","        x = self.dropout(x)\n","        x = self.conv1(x, edge_index, edge_weight)\n","        x = self.elu(x)\n","        x = self.dropout(x)\n","        x = self.conv2(x, edge_index, edge_weight)\n","        if labels is None:\n","            return x\n","\n","        loss = nn.CrossEntropyLoss(weight=weights)(x, labels)\n","        return x, loss\n","\n","class OneLayerGCN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, dropout=0.1):\n","        super(OneLayerGCN, self).__init__()\n","        torch.manual_seed(42)\n","        self.conv = GCNConv(input_size, output_size, cached=True, improved=True, add_self_loops=True, normalize=not use_gdc)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_weight: torch.Tensor, labels: torch.Tensor = None):\n","        x = self.dropout(x)\n","        x = self.conv(x, edge_index, edge_weight)\n","        if labels is None:\n","            return x\n","\n","        loss = nn.CrossEntropyLoss(weight=weights)(x, labels)\n","        return x, loss\n","\n","class TwoLayerGCN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, dropout=0.1):\n","        super(TwoLayerGCN, self).__init__()\n","        torch.manual_seed(42)\n","        self.conv1 = GCNConv(input_size, hidden_size, cached=True, improved=True, add_self_loops=True, normalize=not use_gdc)\n","        self.conv2 = GCNConv(hidden_size, output_size, cached=True, improved=True, add_self_loops=True, normalize=not use_gdc)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_weight: torch.Tensor, labels: torch.Tensor = None):\n","        x = self.dropout(x)\n","        x = self.conv1(x, edge_index, edge_weight)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.conv2(x, edge_index, edge_weight)\n","        if labels is None:\n","            return x\n","\n","        loss = nn.CrossEntropyLoss(weight=weights)(x, labels)\n","        return x, loss\n","\n","class ThreeLayerGCN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, dropout=0.1):\n","        super(ThreeLayerGCN, self).__init__()\n","        torch.manual_seed(42)\n","        self.conv1 = GCNConv(input_size, hidden_size, cached=True, improved=True, add_self_loops=True, normalize=not use_gdc)\n","        self.conv2 = GCNConv(hidden_size, hidden_size, cached=True, improved=True, add_self_loops=True, normalize=not use_gdc)\n","        self.conv3 = GCNConv(hidden_size, output_size, cached=True, improved=True, add_self_loops=True, normalize=not use_gdc)\n","        self.relu1 = nn.ReLU()\n","        self.relu2 = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_weight: torch.Tensor, labels: torch.Tensor = None):\n","        x = self.dropout(x)\n","        x = self.conv1(x, edge_index, edge_weight)\n","        x = self.relu1(x)\n","        x = self.dropout(x)\n","        x = self.conv2(x, edge_index, edge_weight)\n","        x = self.relu2(x)\n","        x = self.dropout(x)\n","        x = self.conv3(x, edge_index, edge_weight)\n","        if labels is None:\n","            return x\n","\n","        loss = nn.CrossEntropyLoss(weight=weights)(x, labels)\n","        return x, loss\n","\n","class GUNet(torch.nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, dropout=0.6):\n","        super().__init__()\n","        pool_ratios = [2000 / data.num_nodes, 0.5]\n","        self.unet = GraphUNet(input_size, hidden_size, output_size,\n","                              depth=3, pool_ratios=pool_ratios)\n","\n","    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_weight: torch.Tensor, labels: torch.Tensor = None):\n","        edge_index, _ = dropout_adj(edge_index, edge_attr=edge_weight, p=0.2,\n","                                    force_undirected=True,\n","                                    num_nodes=data.num_nodes,\n","                                    training=self.training)\n","        x = F.dropout(data.x, p=0.92, training=self.training)\n","\n","        x = self.unet(x, edge_index)\n","        if labels is None:\n","            return x\n","\n","        loss = nn.CrossEntropyLoss(weight=weights)(x, labels)\n","        return x, loss"]},{"cell_type":"code","source":["import numpy as np\n","from matplotlib import pyplot as plt\n","def my_plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=plt.cm.Blues):\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(target_names))\n","    plt.xticks(tick_marks, target_names, rotation=45)\n","    plt.yticks(tick_marks, target_names)\n","    plt.tight_layout()\n","\n","    width, height = cm.shape\n","\n","    for x in range(width):\n","        for y in range(height):\n","            plt.annotate(str(cm[x][y]), xy=(y, x), \n","                        horizontalalignment='center',\n","                        verticalalignment='center')\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","def plot_history(history, eval_train=False):\n","    fig, axs = plt.subplots(1, 3)\n","    if eval_train: leg=['train','val']\n","    else: leg=['val']\n","    fig.set_figheight(7)\n","    fig.set_figwidth(35)\n","    axs[0].set_title('Loss')\n","    if eval_train: axs[0].plot(history['train loss'])\n","    axs[0].plot(history['val loss'])\n","    axs[0].set(ylabel='loss')\n","    axs[1].set_title('Accuracy')\n","    if eval_train: axs[1].plot(history['train acc'])\n","    axs[1].plot(history['val acc'])\n","    axs[1].set(ylabel='accuracy')\n","    axs[2].set_title('MCC')\n","    if eval_train: axs[2].plot(history['train mcc'])\n","    axs[2].plot(history['val mcc'])\n","    axs[2].set(ylabel='mcc')\n","    for ax in axs.flat:\n","        ax.set(xlabel='epochs')\n","        ax.legend(leg, loc='upper left')\n","    plt.show()"],"metadata":{"id":"u-4CIFhUvteK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# One-shot validation"],"metadata":{"id":"1OB9B-O7vNrV"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lppB5F4MqYU8","executionInfo":{"status":"error","timestamp":1649408749348,"user_tz":-120,"elapsed":845,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"}},"outputId":"d08b56c5-f0aa-414a-b626-a78f3baa1a4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["ChebNetGCN(\n","  (input_conv): ChebConv(14, 16, K=2, normalization=sym)\n","  (hidden_convs): ModuleList()\n","  (output_conv): ChebConv(16, 2, K=2, normalization=sym)\n",")\n","Training started:\n","\tNum Epochs = 100\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/100 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-664aa7e19b98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# evaluating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-45-7ca7b6fc415f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, features, train_labels, val_labels, edge_index, edge_weights, device, run_config, log, eval_train)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0meval_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training loss = {loss.item():.4f}, \"\u001b[0m \u001b[0;34mf\"val loss = {val_loss:.4f}, val acc = {val_accuracy:.2f}, val mcc = {val_mcc:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-45-7ca7b6fc415f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, features, test_labels, edge_index, edge_weights, device)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mtrue_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_labels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_label\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpredicted_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mmcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mmatthews_corrcoef\u001b[0;34m(y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m     \"\"\"\n\u001b[0;32m--> 892\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be class 'SparseSeries' or 'SparseArray'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_multilabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVisibleDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVisibleDeprecationWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;31m# dtype=object should be provided explicitly for ragged arrays,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."]}],"source":["%%script echo skipping\n","def set_labels(initial_labels, set_mask, ignore_label):\n","    initial_labels[~set_mask] = ignore_label\n","    return initial_labels\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","ignore_index = nn.CrossEntropyLoss().ignore_index  # = -100, used to ignore not allowed labels in CE loss\n","train_labels = set_labels(data.y.clone(), data.train_mask, ignore_index)\n","val_labels = set_labels(data.y.clone(), data.val_mask, ignore_index)\n","test_labels = set_labels(data.y.clone(), data.test_mask, ignore_index)\n","\n","# training parameters\n","run_config = RunConfig(learning_rate=0.01, num_epochs=100, weight_decay=5e-4, output_dir=\"./gcn-pytorch/saved/\")\n","\n","model = ChebNetGCN(input_size=data.x.shape[1],hidden_size=16,output_size=data.num_classes,dropout=0)\n","#model = GUNet(input_size=data.x.shape[1],hidden_size=16,output_size=data.num_classes,dropout=0)\n","#model = GAT(input_size=data.x.shape[1],hidden_size=8,output_size=data.num_classes,dropout=0)\n","print(model)\n","\n","# training\n","trainer = Trainer(model)\n","history = trainer.train(data.x, train_labels, val_labels, data.edge_index, data.edge_attr, device, run_config, log=True)\n","\n","# evaluating\n","ce_loss, accuracy, mcc, cm, preds = trainer.evaluate(data.x, test_labels, data.edge_index, data.edge_attr, device)\n","print(f'\\nPerformance on kidney:\\n- test accuracy = {accuracy:.3f}\\n- test mcc = {mcc:.3f}\\n')\n","my_plot_confusion_matrix(cm, target_names=classes_mapping.keys())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"elaNxo-ZqYU9","executionInfo":{"status":"ok","timestamp":1649407982398,"user_tz":-120,"elapsed":819,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"}},"outputId":"ea0a2831-02b3-4136-a3dd-fa71cc916bd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["skipping\n"]}],"source":["%%script echo skipping\n","plot_history(history)"]},{"cell_type":"markdown","source":["# k-fold validation"],"metadata":{"id":"6gmpV5So5_rV"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"id":"l89paGzXqYU9","executionInfo":{"status":"error","timestamp":1649408660416,"user_tz":-120,"elapsed":723,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"}},"outputId":"84b25eae-ff38-4901-a686-16669f1ef963"},"outputs":[{"output_type":"stream","name":"stderr","text":["5-fold:   0%|          | 0/5 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["cuda\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-8273c6eea501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# evaluating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-45-7ca7b6fc415f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, features, train_labels, val_labels, edge_index, edge_weights, device, run_config, log, eval_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-42-f8012167cff2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight, labels)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument weight in method wrapper_nll_loss_forward)"]}],"source":["#@title Choose GNN { form-width: \"20%\" }\n","netmodel = \"OneLayerGCN\" #@param [\"OneLayerGCN\", \"TwoLayerGCN\", \"ChebNetGCN\"]\n","epochs = 200 #@param {type:\"slider\", min:10, max:1000, step:10}\n","def set_labels(initial_labels, set_mask, ignore_label):\n","    initial_labels[~set_mask] = ignore_label\n","    return initial_labels\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n","from sklearn.metrics import *\n","from tqdm import tqdm\n","nfolds = 5\n","kf = KFold(n_splits=nfolds)\n","accuracies = []\n","mccs = []\n","cmaccumulated = np.array([[0,0],[0,0]])\n","columns_names = [\"Accuracy\",\"BA\", \"Sensitivity\", \"Specificity\",\"MCC\", 'CM']\n","scores = pd.DataFrame(columns=columns_names)\n","for fold, (train_index, test_index) in enumerate(tqdm(kf.split(np.arange(data.num_nodes)), total=kf.get_n_splits(), desc=f\"{nfolds}-fold\")):\n","    train_labels = y[train_index]\n","    train_index, val_index = train_test_split(train_index, test_size=0.025, stratify=train_labels)\n","    tr_index  = torch.tensor(train_index)\n","    val_index  = torch.tensor(val_index)\n","    ts_index = torch.tensor(test_index)\n","    train_mask = torch.BoolTensor([False]*data.num_nodes)\n","    val_mask = torch.BoolTensor([False]*data.num_nodes)\n","    test_mask = torch.BoolTensor([False]*data.num_nodes)\n","    train_mask.scatter_(0, tr_index, True)\n","    val_mask.scatter_(0, val_index, True)\n","    test_mask.scatter_(0, ts_index, True)\n","\n","    ignore_index = nn.CrossEntropyLoss().ignore_index  # = -100, used to ignore not allowed labels in CE loss\n","    train_labels = set_labels(data.y.clone(), train_mask, ignore_index)\n","    val_labels = set_labels(data.y.clone(), val_mask, ignore_index)\n","    test_labels = set_labels(data.y.clone(), test_mask, ignore_index)\n","    # training parameters\n","    run_config = RunConfig(learning_rate=0.01, num_epochs=epochs, weight_decay=5e-4)\n","    model = globals()[netmodel](input_size=data.x.shape[1],hidden_size=16,output_size=data.num_classes,dropout=0)\n","\n","    # training\n","    trainer = Trainer(model)\n","    print(device)\n","    trainer.train(data.x, train_labels, val_labels, data.edge_index, data.edge_attr, device, run_config, log=False)\n","\n","    # evaluating\n","    ce_loss, accuracy, mcc, cm, preds = trainer.evaluate(data.x, test_labels, data.edge_index, data.edge_attr, device)\n","    accuracies.append(accuracy)\n","    mccs.append(mcc)\n","    cmaccumulated += cm\n","    true_label = test_labels[test_labels != -100]\n","    scores = scores.append(pd.DataFrame([[accuracy_score(true_label.cpu().numpy(), preds.cpu().numpy()), balanced_accuracy_score(true_label.cpu().numpy(), preds.cpu().numpy()), \n","        cm[0,0]/(cm[0,0]+cm[0,1]), cm[1,1]/(cm[1,0]+cm[1,1]), \n","        matthews_corrcoef(true_label.cpu().numpy(), preds.cpu().numpy()), cm]], columns=columns_names, index=[fold]))\n","df_scores = pd.DataFrame(scores.mean(axis=0)).T\n","df_scores.index=[f'{netmodel}']\n","df_scores['CM'] = [cmaccumulated]\n","print(df_scores.to_latex())\n","df_scores\n","my_plot_confusion_matrix(cmaccumulated, target_names=classes_mapping.keys())\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"EssentialGenes (SV Paper GCN) colab.ipynb","provenance":[],"toc_visible":true},"interpreter":{"hash":"bc6e667b201477635ba32fc377e71e93fe0ce3fc2d2fb508931525558f52d375"},"kernelspec":{"display_name":"Python 3.8.3 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}