{"cells":[{"cell_type":"markdown","metadata":{"id":"MNgwF_IjTjNq"},"source":["# Loading required libraries"]},{"cell_type":"markdown","metadata":{"id":"NgVRqVeuq5GN"},"source":["### Install Pytorch libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26515,"status":"ok","timestamp":1651303169776,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"},"user_tz":-120},"id":"90eWJsb5q9j0","outputId":"3bf42d0a-6ec3-47c5-a569-737ef343c6a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 7.9 MB 35.0 MB/s \n","\u001b[K     |████████████████████████████████| 3.5 MB 34.5 MB/s \n","\u001b[K     |████████████████████████████████| 2.5 MB 18.0 MB/s \n","\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n","!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ddc1yRocTjNr","executionInfo":{"status":"ok","timestamp":1651303171891,"user_tz":-120,"elapsed":2121,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"}}},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","import random\n","import numpy as np\n","import torch\n","def set_seed(seed=1):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","\n","set_seed()"]},{"cell_type":"markdown","metadata":{"id":"jwXYNEIFff-l"},"source":["# Download dataset from Github"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1242,"status":"ok","timestamp":1651303173129,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"},"user_tz":-120},"id":"ykT1KO_4eqvK","outputId":"3ca12d3c-0a7b-417c-a09f-5526cd3f4f37"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-30 07:19:31--  https://raw.githubusercontent.com/giordamaug/BIONETdatasets/main/CSV/integratedcrispr/edges_integrated2.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 39025931 (37M) [text/plain]\n","Saving to: ‘edges_integrated2.csv’\n","\n","edges_integrated2.c 100%[===================>]  37.22M  --.-KB/s    in 0.1s    \n","\n","2022-04-30 07:19:32 (377 MB/s) - ‘edges_integrated2.csv’ saved [39025931/39025931]\n","\n","--2022-04-30 07:19:32--  https://raw.githubusercontent.com/giordamaug/BIONETdatasets/main/CSV/integratedcrispr/nodes_integrated2_update_attr_label_avana0_wang_crispr.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10647374 (10M) [text/plain]\n","Saving to: ‘nodes_integrated2_update_attr_label_avana0_wang_crispr.csv’\n","\n","nodes_integrated2_u 100%[===================>]  10.15M  --.-KB/s    in 0.04s   \n","\n","2022-04-30 07:19:32 (242 MB/s) - ‘nodes_integrated2_update_attr_label_avana0_wang_crispr.csv’ saved [10647374/10647374]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/giordamaug/BIONETdatasets/main/CSV/integratedcrispr/edges_integrated2.csv\n","!wget https://raw.githubusercontent.com/giordamaug/BIONETdatasets/main/CSV/integratedcrispr/nodes_integrated2_update_attr_label_avana0_wang_crispr.csv"]},{"cell_type":"markdown","metadata":{"id":"dL6HwnA8Y1vv"},"source":["# Load the attributes and labels from CSV\n","\n","All node/gene attributes and labels are in one file. Firs we devide attributes (numeri) from labels (non-numeric) columns.\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":634,"status":"ok","timestamp":1651303173761,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"},"user_tz":-120},"id":"UpDEhD9Cfu8l"},"outputs":[],"source":["import pandas as pd\n","from sklearn import preprocessing\n","node_name, label_name = 'name', 'label_CS_ACH_most_freq'\n","# read node attributes\n","df = pd.read_csv('/content/nodes_integrated2_update_attr_label_avana0_wang_crispr.csv', \n","                 sep='\\t', index_col=node_name)   # load csv and set 'name' as index\n","x = df.select_dtypes(include=np.number)           # Attributes are numeric columns\n","labels = df.select_dtypes(exclude=np.number)      # labels are not numeric columns"]},{"cell_type":"markdown","metadata":{"id":"T-NvE8jjgL8h"},"source":["# Set the label\n","The label is one column or a grouping of values from one label column. In the paper we considered the ten values of `label_CS_ACH_most_freq`, and we grouped as following:\n","*   `CS0` = `E`ssential class\n","*   `CS6`-`CS9` = `NE` non essential class\n","\n","The new label name is `CS0_vs_CS6-9`\n","\n","\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1651303173761,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"},"user_tz":-120},"id":"-v8d4IUvF9Yj","outputId":"e099c7b3-877f-4d65-ed08-8681030d5841"},"outputs":[{"output_type":"stream","name":"stdout","text":["Selected 3814 genes\n"]}],"source":["E_class, NE_class = ['CS0'], ['CS6', 'CS7', 'CS8', 'CS9']\n","new_label_name = 'CS0_vs_CS6-9'\n","labels[new_label_name] = labels.apply(lambda row: 'E' if row[label_name] in E_class \\\n","                                      else 'NE' if row[label_name] in NE_class \\\n","                                      else row[label_name], axis=1)\n","labels = labels[labels[new_label_name].isin(['E', 'NE']) == True]       # drop any row contaning NaN or SC1-SC5 as value\n","genes = labels.index.values\n","print(f'Selected {len(genes)} genes')"]},{"cell_type":"markdown","metadata":{"id":"5snibVTZIm-d"},"source":["# Encode the label"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1651303173762,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"},"user_tz":-120},"id":"AG6j1sAJfgAS","outputId":"1fe1811e-2d1c-42db-81bc-f620e0bae98b"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'E': 0, 'NE': 1} Counter({1: 3069, 0: 745})\n"]}],"source":["from sklearn import preprocessing\n","from collections import Counter\n","encoder = preprocessing.LabelEncoder()\n","y = encoder.fit_transform(labels[new_label_name].values)  \n","classes_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n","print(classes_mapping, Counter(y))"]},{"cell_type":"markdown","metadata":{"id":"KGZqjWBcmNM6"},"source":["# Load the PPI network\n","The PPI networks is loaded from a CSV file, where\n","*   `A` is the column name for edge source (gene name)\n","*   `B` is the column name for edge target (gene name)\n","*   `weight` is the column name for edge weight\n","Only some method use the PPI netoworks, as an example all GCN methods, and Node2Vec.\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":642,"status":"ok","timestamp":1651303174396,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"},"user_tz":-120},"id":"ku9EUnJfmMF4"},"outputs":[],"source":["ppi = pd.read_csv('/content/edges_integrated2.csv', sep='\\t')              # read ppi from CSV file\n","ppi = ppi.loc[((ppi['A'].isin(genes)) & (ppi['B'].isin(genes)))]           # reduce PPI only to selected nodes/genes\n","idxlbl = labels.reset_index(drop=True)\n","idxlbl[node_name] = labels.index\n","map_gene_to_idx = { v[node_name]: i  for i,v in idxlbl.to_dict('Index').items() }\n","vfunc = np.vectorize(lambda t: map_gene_to_idx[t])\n","edges_index = torch.from_numpy(vfunc(ppi[['A','B']].to_numpy().T)) "]},{"cell_type":"markdown","metadata":{"id":"Vmbko7ys1m-d"},"source":["# Select attributes to be used\n","We identified three sets of attributes:\n","1. bio attributes, related to gene information (such as, expression, etc.)\n","2. net attributes, derived from role of gene/node in the network (such as, degree, centrality, etc.)\n","3. GTEX-* attribute, additional biological information of genes \n","\n","In this code snippets the sets of attibutes are defines, and you may choose to subtract some of them from the matrix of node attributes \n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1651303174396,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"},"user_tz":-120},"id":"e1eTV5Ky2R9_"},"outputs":[],"source":["#@title Choose attributes { form-width: \"20%\" }\n","import re\n","bio_attr = True #@param {type:\"boolean\"}\n","net_attr = True #@param {type:\"boolean\"}\n","gtex_attr = True #@param {type:\"boolean\"}\n","bio_attributes = ['gc_content', 'Gtex_kidney', 'gene_disease_ass_count', 'oncodb_expression','orth_count', 'gene_length', \\\n","       'HPA_kidney', 'mf_coal', 'bp_coal', 'cc_coal', 'biogrid_coal', 'kegg_coal', 'reactome_coal', 'ucsc_tfbs_coal', \\\n","       'up_tissue_coal', 'transcript_count']  if bio_attr else []\n","net_attributes = ['degree', 'ecc', 'clos', 'betw', 'eigen', 'hub', 'trans', 'PR', 'triangles_numb', 'motif1', \\\n","        'motif2', 'motif3', 'motif5', 'strength'] if net_attr else []\n","r = re.compile('^GTEX*')\n","gtex_attributes = list(filter(r.match, x.columns)) if gtex_attr else []\n","x = x.filter(items=bio_attributes+gtex_attributes+net_attributes)"]},{"cell_type":"markdown","metadata":{"id":"B_Pz7CiWtKa3"},"source":["## Normalize attributes\n","In this snippet of code the matrix of node attributes is corrected by filling NaN with themean in the columns, while Infinte value with maximum. \n","\n","The attribute matrix is also reduce by removing all rows correspondning to node not considered, i.e. deleted becaus no label was associated to them."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":340,"status":"ok","timestamp":1651303174734,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"},"user_tz":-120},"id":"pUXJiVentM44","outputId":"0ab1d214-6197-4325-ab45-eb3e56d52e9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fixing NaN and infinity in X matrix...Found 15919 NaN values and 0 Inf values\n","X attributes normalization (zscore)...\n","New attribute matrix x(3814, 119)\n"]}],"source":["#@title Normalization modes { form-width: \"30%\" }\n","normalize_node = \"zscore\" #@param [\"\", \"zscore\", \"minmax\"]\n","print(f'Fixing NaN and infinity in X matrix...', end='')\n","print(f'Found {x.isnull().sum().sum()} NaN values and {np.isinf(x).values.sum()} Inf values')\n","highest_non_inf = x.max().loc[lambda v: v<np.Inf].max()    # fix infinity (replace with max)\n","x.replace(np.Inf, highest_non_inf)\n","for col in x.columns[x.isna().any()].tolist():\n","  mean_value=x[col].mean()          # Replace NaNs in column with the  mean of values in the same column\n","  if mean_value is not np.nan:\n","    x[col].fillna(value=mean_value, inplace=True)\n","  else:\n","    x = x.drop(col, 1)\n","if normalize_node == 'minmax':\n","  print(\"X attributes normalization (minmax)...\")\n","  x = (x-x.min())/(x.max()-x.min())\n","elif normalize_node == 'zscore':\n","  print(\"X attributes normalization (zscore)...\")\n","  x = (x-x.mean())/x.std()\n","x = x.loc[genes]\n","print(f'New attribute matrix x{x.shape}')"]},{"cell_type":"markdown","metadata":{"id":"HAkzHzMYbAQh"},"source":["# k-fold cross validation with Node2Vec"]},{"cell_type":"markdown","metadata":{"id":"ulCMrjlowPPa"},"source":["### MLP model"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"6-JS-m1wwR49","executionInfo":{"status":"ok","timestamp":1651303174734,"user_tz":-120,"elapsed":3,"user":{"displayName":"Maurizio Giordano","userId":"11661605724852130605"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","class Loss():\n","    def __init__(self, y):\n","        self.y = y\n","        self.pos_mask = y == 1\n","        self.neg_mask = y == 0\n","\n","    def __call__(self, out):\n","        pos_mask = self.pos_mask\n","        neg_mask = self.neg_mask\n","        loss_p = F.binary_cross_entropy_with_logits(\n","            out[pos_mask].squeeze(), self.y[self.pos_mask].to(DEVICE))\n","        loss_n = F.binary_cross_entropy_with_logits(\n","            out[neg_mask].squeeze(), self.y[neg_mask].to(DEVICE))\n","        loss = loss_p + loss_n\n","        return loss\n","\n","def mlp_fit_predict(train_x, train_y, test_x, val=None, return_val_probs=False, log=False):\n","    epochs = 1000\n","\n","    in_feats = train_x.shape[1]\n","    model = nn.Sequential(\n","        nn.Linear(in_feats, 32),\n","        nn.ReLU(),\n","        nn.Dropout(0.2),\n","        nn.Linear(32, 1))\n","    optimizer = torch.optim.Adam(model.parameters())\n","\n","    lossf = Loss(train_y)\n","\n","    if val is not None:\n","        val_x, val_y = val\n","        lossf_val = Loss(val_y)\n","\n","    model.train()\n","    model.to(DEVICE)\n","\n","    patience, cur_es = 3, 0\n","    val_loss_old = np.Inf\n","\n","    for i in range(epochs):\n","        out = model(train_x)\n","        loss = lossf(out)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        if (i % 10) == 0:\n","            if val is not None:\n","                model.eval()\n","                with torch.no_grad():\n","                    loss_val = lossf_val(model(val_x))\n","                if log: print(f'{i}. Train loss:', loss.detach().cpu().numpy(), ' |  Val Loss:', loss_val.detach().cpu().numpy())\n","                model.train()\n","\n","                if val_loss_old < loss_val:\n","                    cur_es += 1\n","                else:\n","                    cur_es = 0\n","                val_loss_old = loss_val\n","\n","                if cur_es == patience:\n","                    break\n","\n","    model.eval()\n","    with torch.no_grad():\n","        out = model(test_x).cpu()\n","    probs = torch.sigmoid(out).numpy()\n","\n","    if return_val_probs:\n","        with torch.no_grad():\n","            out = model(val_x).cpu()\n","        val_probs = torch.sigmoid(out).numpy()\n","\n","        return probs, val_probs\n","\n","    return probs"]},{"cell_type":"markdown","metadata":{"id":"11kiH2juqU-M"},"source":["### Node2vec model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOqAt1Nua491"},"outputs":[],"source":["from sklearn.svm import SVC\n","from torch_geometric.nn.models import Node2Vec\n","import torch.optim as optim\n","import torch_cluster\n","PARAMS = {\n","    'embedding_dim': 128,\n","    'walk_length': 64,\n","    'context_size': 64,\n","    'walks_per_node': 64,\n","    'num_negative_samples': 1,\n","}\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def train_epoch(n2v, n2v_loader, n2v_optimizer, X, train_y, train_mask, val_y, val_mask, test_mask, epochs=100, log=False):\n","\n","    X = X.to(DEVICE)\n","    train_y = train_y.to(DEVICE)\n","    val_y = val_y.to(DEVICE)\n","    Z = None\n","\n","    n2v.train()\n","    for i in range(epochs):\n","        n2v_train_loss = 0\n","\n","        for (pos_rw, neg_rw) in n2v_loader:\n","            n2v_optimizer.zero_grad()\n","            loss = n2v.loss(pos_rw.to(DEVICE), neg_rw.to(DEVICE))\n","            loss.backward()\n","            n2v_optimizer.step()\n","            n2v_train_loss += loss.data.item()\n","        if log: print(f'Epoch {i}. N2V Train_Loss:', n2v_train_loss)\n","    n2v.eval()\n","    Z = n2v().detach()\n","\n","    if X is None:\n","        train_x = Z[train_mask]\n","        val_x = Z[val_mask]\n","        test_x = Z[test_mask]\n","    elif Z is not None:\n","        train_x = torch.cat([Z[train_mask], X[train_mask]], dim=1)\n","        val_x = torch.cat([Z[val_mask], X[val_mask]], dim=1)\n","        test_x = torch.cat([Z[test_mask], X[test_mask]], dim=1)\n","    else:\n","        train_x = X[train_mask]\n","        val_x = X[val_mask]\n","        test_x = X[test_mask]\n","    if log: print('train_X.shape', train_x.shape)\n","\n","    probs, val_probs = mlp_fit_predict(\n","        train_x, train_y, test_x, val=(val_x, val_y), return_val_probs=True)\n","    val_roc_auc = roc_auc_score(val_y.cpu().numpy(), val_probs)\n","\n","    if log: print('Validation ROC_AUC:', val_roc_auc)\n","    return probs, val_roc_auc\n","\n","\n","def n2v_fit_predict(edge_index, X, train_y, train_mask, val_y, val_mask, test_mask, epochs=100, log=False):\n","    n2v = Node2Vec(edge_index, **PARAMS).to(DEVICE)\n","    n2v_loader = n2v.loader(batch_size=128, shuffle=True, num_workers=0)\n","    n2v_optimizer = optim.Adam(n2v.parameters(), lr=LR)\n","\n","    probs, val_roc_auc = train_epoch(\n","        n2v, n2v_loader, n2v_optimizer, X, train_y, train_mask, val_y, val_mask, test_mask, epochs=epochs, log=log)\n","\n","    return probs\n"]},{"cell_type":"markdown","metadata":{"id":"L2bmY_k2KlE_"},"source":["### Validate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8bXIozL_bC_x"},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n","from tqdm import tqdm\n","from sklearn.metrics import *\n","\n","set_seed(1)\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","NFOLDS = 5\n","LR = 1e-2\n","WEIGHT_DECAY = 5e-4\n","EPOCHS = 50\n","\n","X = torch.tensor(x.to_numpy(), dtype=torch.float)\n","kf = KFold(n_splits=NFOLDS)\n","cma = np.array([[0,0],[0,0]])\n","columns_names = [\"Accuracy\",\"BA\", \"Sensitivity\", \"Specificity\",\"MCC\", 'CM']\n","scores = pd.DataFrame(columns=columns_names)\n","mm = np.array([], dtype=np.int)\n","predictions = np.array([])\n","for fold, (train_index, test_idx) in enumerate(tqdm(kf.split(np.arange(len(X))), total=kf.get_n_splits(), desc=f\"{NFOLDS}-fold\")):\n","    train_idx, val_idx = train_test_split(train_index, test_size=0.05, stratify=y[train_index])\n","    mm = np.concatenate((mm, test_idx))\n","    train_y = torch.tensor(y[train_idx], dtype=torch.float)\n","    val_y = torch.tensor(y[val_idx], dtype=torch.float)\n","    test_y = torch.tensor(y[test_idx], dtype=torch.float).to(DEVICE)\n","    train_x = torch.tensor(X[train_idx], dtype=torch.float).to(DEVICE)\n","    val_x = torch.tensor(X[val_idx], dtype=torch.float).to(DEVICE)\n","    test_x = torch.tensor(X[test_idx], dtype=torch.float).to(DEVICE)\n","    probs = n2v_fit_predict(edges_index, X, train_y, train_idx, val_y, val_idx, test_idx, epochs=EPOCHS, log=False)\n","    preds = (probs > 0.5) * 1\n","    predictions = np.concatenate((predictions, preds.ravel()))\n","    cm = confusion_matrix(test_y.cpu().numpy(),preds)\n","    cma += cm\n","    scores = scores.append(pd.DataFrame([[accuracy_score(test_y.cpu().numpy(), preds), balanced_accuracy_score(test_y.cpu().numpy(), preds), \n","        cm[0,0]/(cm[0,0]+cm[0,1]), cm[1,1]/(cm[1,0]+cm[1,1]), \n","        matthews_corrcoef(test_y.cpu().numpy(), preds), cm]], columns=columns_names, index=[fold]))\n","df_scores = pd.DataFrame(scores.mean(axis=0)).T\n","df_scores.index=[f'N2V']\n","df_scores['CM'] = [cma]\n","print(df_scores.to_latex())\n","p = np.zeros(len(y))\n","p[mm] = predictions"]},{"cell_type":"markdown","source":["# Print predictions"],"metadata":{"id":"8TsJPJYWVKWo"}},{"cell_type":"code","source":["print(np.unique(y+p, return_counts=True))\n","labels['predictions'] = p\n","labels[(labels['predictions'] == 0 ) & ( labels['CS0_vs_CS6-9'] == 'E')].index\n","f = open(\"N2V+MLP_Egenes.csv\", \"w\")\n","f.write('\\n'.join([str(e) for e in list(labels[(labels['predictions'] == 0 ) & ( labels['CS0_vs_CS6-9'] == 'E')].index)]))\n","f.close()\n","labels[['CS0_vs_CS6-9', 'predictions']].to_csv('N2V+MLP_Predictions.csv')"],"metadata":{"id":"t7Q2gF8t4p12"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"EssentialGenes (SV Paper N2V) colab.ipynb","provenance":[{"file_id":"1s7mooyOC1N-tIlPbmwFVPFlhw1vNAxbK","timestamp":1651302781975}],"toc_visible":true},"interpreter":{"hash":"bc6e667b201477635ba32fc377e71e93fe0ce3fc2d2fb508931525558f52d375"},"kernelspec":{"display_name":"Python 3.8.3 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}