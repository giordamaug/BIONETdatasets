{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giordamaug/BIONETdatasets/blob/main/TUD/notebooks/GIN_Spectr\n",
        "al_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/giordamaug/BIONETdatasets/main?filepath=TUD%2Fnotebooks%2FGIN_Spectral_example.ipynb)\n",
        "<a href=\"https://kaggle.com/kernels/welcome?src=https://github.com/giordamaug/BIONETdatasets/blob/main/TUD/notebooks/GIN_Spectral_example.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kux3bRpFEEoM"
      },
      "source": [
        "# Cloning BIONETdatasets repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CemjxolD1na"
      },
      "outputs": [],
      "source": [
        "!git clone http://github.com/giordamaug/BIONETdatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daN-NtkfEfZw"
      },
      "outputs": [],
      "source": [
        "!pip install -q spektral\n",
        "!pip install -q sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-ofwbmSJrpt"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eTgDV3DEwyM"
      },
      "outputs": [],
      "source": [
        "#@title select the dataset { form-width: \"30%\" }\n",
        "dataname = \"Mutagenicity\" #@param [\"ogbg-molbace\", \"ogbg-molbbbp\", \"KIDNEY\", \"MUTAG\", \"PROTEINS\", \"Mutagenicity\" ]\n",
        "import shutil\n",
        "import os\n",
        "shutil.unpack_archive(f'/content/BIONETdatasets/TUD/datasets/{dataname}.zip', '/content')\n",
        "import sys\n",
        "sys.path.append('BIONETdatasets/TUD')\n",
        "from wrappers.spektral_wrapper import MyTUDataset\n",
        "dataset = MyTUDataset(dataname, path=dataname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeXcGIzPl3Yv"
      },
      "source": [
        "# Apply GIN model on dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNwlXkHoJvID"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This example shows how to perform graph classification with a simple Graph\n",
        "Isomorphism Network.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tqdm.notebook as tq\n",
        "from time import time\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from spektral.data import DisjointLoader\n",
        "from spektral.datasets import TUDataset\n",
        "from spektral.layers import GINConv, GlobalSumPool, GlobalAvgPool\n",
        "\n",
        "################################################################################\n",
        "# Config\n",
        "################################################################################\n",
        "#@title Parameters { form-width: \"30%\" }\n",
        "learning_rate = 0.001  #@param {type:\"number\"}\n",
        "epochs = 100 #@param {type:\"slider\", min:0, max:500, step:20}\n",
        "channels = 64 #@param {type:\"slider\", min:16, max:128, step:16}\n",
        "batch_size = 10  #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "layers = 3  #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "folds = 5  #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "verbose = False #@param {type:\"boolean\"}\n",
        "seed = 42 #@param {type:\"number\"}\n",
        "\n",
        "# Parameters\n",
        "F = dataset.n_node_features  # Dimension of node features\n",
        "n_out = dataset.n_labels  # Dimension of the target\n",
        "\n",
        "################################################################################\n",
        "# Build model\n",
        "################################################################################\n",
        "class GIN0(Model):\n",
        "    def __init__(self, channels, n_layers):\n",
        "        super().__init__()\n",
        "        self.conv1 = GINConv(channels, epsilon=0, mlp_hidden=[channels, channels])\n",
        "        self.convs = []\n",
        "        for _ in range(1, n_layers):\n",
        "            self.convs.append(\n",
        "                GINConv(channels, epsilon=0, mlp_hidden=[channels, channels])\n",
        "            )\n",
        "        self.pool = GlobalAvgPool()\n",
        "        self.dense1 = Dense(channels, activation=\"relu\")\n",
        "        self.dropout = Dropout(0.5)\n",
        "        self.dense2 = Dense(n_out, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, a, = inputs[0:2]\n",
        "        i = inputs[-1]\n",
        "        #x, a, i = inputs\n",
        "        x = self.conv1([x, a])\n",
        "        for conv in self.convs:\n",
        "            x = conv([x, a])\n",
        "        x = self.pool([x, i])\n",
        "        x = self.dense1(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.dense2(x)\n",
        "\n",
        "\n",
        "start = time()\n",
        "\n",
        "# Cross Validation loop\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "targets = [g.y.dot(1 << np.arange(g.y.size)[::-1]) for g in dataset]\n",
        "sp = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
        "results = []\n",
        "for idx_tr, idx_te in tq.tqdm(list(sp.split(dataset, targets)), desc=\"fold: \"):\n",
        "  dataset_tr, dataset_te = dataset[idx_tr], dataset[idx_te]\n",
        "\n",
        "  loader_tr = DisjointLoader(dataset_tr, batch_size=batch_size, epochs=epochs)\n",
        "  loader_te = DisjointLoader(dataset_te, batch_size=batch_size, epochs=1)\n",
        "\n",
        "################################################################################\n",
        "# Fit model\n",
        "################################################################################\n",
        "  @tf.function(input_signature=loader_tr.tf_signature(), experimental_relax_shapes=True)\n",
        "  def train_step(inputs, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_fn(target, predictions) + sum(model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    acc = tf.reduce_mean(categorical_accuracy(target, predictions))\n",
        "    return loss, acc\n",
        "  # Build model\n",
        "  model = GIN0(channels, layers)\n",
        "  optimizer = Adam(learning_rate)\n",
        "  loss_fn = CategoricalCrossentropy()\n",
        "\n",
        "  epoch = step = 0\n",
        "  tresults = []\n",
        "  for batch in loader_tr:\n",
        "    step += 1\n",
        "    loss, acc = train_step(*batch)\n",
        "    tresults.append((loss, acc))\n",
        "    if step == loader_tr.steps_per_epoch:\n",
        "        step = 0\n",
        "        epoch += 1\n",
        "        if verbose: print(\"Ep. {} - Loss: {}. Acc: {}\".format(epoch, *np.mean(tresults, 0)))\n",
        "        tresults = []\n",
        "\n",
        "################################################################################\n",
        "# Evaluate model\n",
        "################################################################################\n",
        "  for batch in loader_te:\n",
        "    inputs, target = batch\n",
        "    predictions = model(inputs, training=False)\n",
        "    results.append(\n",
        "        (\n",
        "            loss_fn(target, predictions),\n",
        "            tf.reduce_mean(categorical_accuracy(target, predictions)),\n",
        "        )\n",
        "    )\n",
        "  if verbose: print(\"Done. Test loss: {}. Test acc: {}\".format(*np.mean(results, 0)))\n",
        "# Timing\n",
        "temp = time() - start\n",
        "hours = temp//3600\n",
        "temp = temp - 3600*hours\n",
        "minutes = temp//60\n",
        "seconds = temp - 60*minutes\n",
        "expired = '%d:%d:%d' %(hours,minutes,seconds)\n",
        "print(\"Done. Test loss: {}. Test acc: {}\".format(*np.mean(results, 0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0-V-LCXmIIk"
      },
      "source": [
        "# Save the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anuEdalOPK-w"
      },
      "outputs": [],
      "source": [
        "method = 'GIN'\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "path = f'{method}_results.csv'\n",
        "if not os.path.exists(path):\n",
        "  dfres = pd.DataFrame(columns=['dataset', 'loss', 'acc', 'folds', 'seed', 'lr', 'epochs', 'batch_size', 'layers', 'channels', 'date', 'elapsed'])\n",
        "  dfres.to_csv(path, index=False)\n",
        "dfres = pd.read_csv(path)\n",
        "dfres = dfres.append({'dataset': dataname,\n",
        "                      'loss': np.mean(results, 0)[0],\n",
        "                      'acc' : np.mean(results, 0)[1], \n",
        "                      'folds' : folds,\n",
        "                      'seed' : seed, \n",
        "                      'lr' : learning_rate, 'epochs' : epochs, 'batch_size' : batch_size, 'layers': layers, 'channels' : channels, \n",
        "                      'date': datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\"),\n",
        "                      'elapsed': expired\n",
        "                      }, ignore_index=True)\n",
        "dfres.to_csv(path, index=False)\n",
        "dfres"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPAI+3EyAQegC+sXQllhlee",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "GIN (Spectral) example.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
